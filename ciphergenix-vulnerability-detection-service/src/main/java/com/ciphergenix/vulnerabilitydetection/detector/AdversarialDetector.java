package com.ciphergenix.vulnerabilitydetection.detector;

import com.ciphergenix.vulnerabilitydetection.model.DetectionResult;
import com.ciphergenix.vulnerabilitydetection.model.DetectionType;
import org.apache.commons.math3.linear.*;
import org.apache.commons.math3.stat.correlation.Covariance;
import org.apache.commons.math3.stat.descriptive.DescriptiveStatistics;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.stereotype.Component;

import java.util.*;

@Component
public class AdversarialDetector {
    
    private static final Logger logger = LoggerFactory.getLogger(AdversarialDetector.class);
    
    @Value("${ciphergenix.vulnerability-detection.adversarial-detection.perturbation-threshold:0.01}")
    private double perturbationThreshold;
    
    @Value("${ciphergenix.vulnerability-detection.adversarial-detection.mahalanobis-threshold:2.5}")
    private double mahalanobisThreshold;
    
    @Value("${ciphergenix.vulnerability-detection.adversarial-detection.reconstruction-error-threshold:0.05}")
    private double reconstructionErrorThreshold;
    
    @Value("${ciphergenix.vulnerability-detection.adversarial-detection.ensemble-weights.gradient-analysis:0.35}")
    private double gradientAnalysisWeight;
    
    @Value("${ciphergenix.vulnerability-detection.adversarial-detection.ensemble-weights.mahalanobis:0.25}")
    private double mahalanobisWeight;
    
    @Value("${ciphergenix.vulnerability-detection.adversarial-detection.ensemble-weights.reconstruction:0.25}")
    private double reconstructionWeight;
    
    @Value("${ciphergenix.vulnerability-detection.adversarial-detection.ensemble-weights.statistical:0.15}")
    private double statisticalWeight;
    
    // Cache for model statistics
    private final Map<String, ModelStatistics> modelStatsCache = new HashMap<>();
    
    public AdversarialDetector() {
        logger.info("AdversarialDetector initialized");
    }
    
    /**
     * Main detection method for adversarial examples
     */
    public DetectionResult detectAdversarial(String sessionId, List<Double> inputData, 
                                           String modelId, Map<String, Object> modelMetadata) {
        long startTime = System.currentTimeMillis();
        logger.info("Starting adversarial detection for session: {} with model: {}", sessionId, modelId);
        
        try {
            // Convert input to array
            double[] input = inputData.stream().mapToDouble(Double::doubleValue).toArray();
            
            // Initialize detection result
            DetectionResult result = new DetectionResult(sessionId, DetectionType.ADVERSARIAL_ATTACK, 
                                                       0.0, false, "Ensemble");
            result.setDatasetSize(1); // Single input
            
            // Get or compute model statistics
            ModelStatistics modelStats = getOrComputeModelStatistics(modelId, modelMetadata);
            
            // Perform gradient analysis
            Map<String, Object> gradientResults = performGradientAnalysis(input, modelStats);
            
            // Perform feature space distance computation
            Map<String, Object> mahalanobisResults = performMahalanobisDistanceAnalysis(input, modelStats);
            
            // Perform reconstruction error analysis
            Map<String, Object> reconstructionResults = performReconstructionErrorAnalysis(input, modelStats);
            
            // Perform statistical tests
            Map<String, Object> statisticalResults = performStatisticalTests(input, modelStats);
            
            // Calculate ensemble decision
            double finalThreatScore = calculateEnsembleScore(gradientResults, mahalanobisResults, 
                                                           reconstructionResults, statisticalResults);
            
            // Determine if adversarial attack is detected
            boolean isAdversarial = finalThreatScore > 0.5; // Threshold for adversarial detection
            
            // Build detection details
            Map<String, String> detectionDetails = buildDetectionDetails(gradientResults, mahalanobisResults,
                                                                        reconstructionResults, statisticalResults);
            
            // Update result
            result.setThreatScore(finalThreatScore);
            result.setIsThreatDetected(isAdversarial);
            result.setDetectionDetails(detectionDetails);
            result.setConfidenceScore(calculateConfidenceScore(finalThreatScore));
            result.setProcessingTimeMs(System.currentTimeMillis() - startTime);
            result.setModelVersion(modelId);
            
            logger.info("Adversarial detection completed for session: {}. Adversarial detected: {}, Score: {}", 
                       sessionId, isAdversarial, finalThreatScore);
            
            return result;
            
        } catch (Exception e) {
            logger.error("Error during adversarial detection for session: {}", sessionId, e);
            DetectionResult errorResult = new DetectionResult(sessionId, DetectionType.ADVERSARIAL_ATTACK, 
                                                            1.0, true, "Error");
            errorResult.setProcessingTimeMs(System.currentTimeMillis() - startTime);
            Map<String, String> errorDetails = new HashMap<>();
            errorDetails.put("error", e.getMessage());
            errorResult.setDetectionDetails(errorDetails);
            return errorResult;
        }
    }
    
    /**
     * Perform gradient-based detection using FGSM, PGD, and C&W attack signatures
     */
    private Map<String, Object> performGradientAnalysis(double[] input, ModelStatistics modelStats) {
        Map<String, Object> results = new HashMap<>();
        
        try {
            // Simulate gradient computation (in practice, this would use actual model gradients)
            double[] simulatedGradients = computeSimulatedGradients(input);
            
            // Calculate gradient norm
            double gradientNorm = calculateL2Norm(simulatedGradients);
            
            // Detect FGSM-like patterns (high gradient magnitude in specific directions)
            double fgsmScore = detectFGSMPattern(simulatedGradients, modelStats);
            
            // Detect PGD-like patterns (iterative perturbations)
            double pgdScore = detectPGDPattern(input, simulatedGradients, modelStats);
            
            // Detect C&W-like patterns (optimized perturbations)
            double cwScore = detectCWPattern(input, simulatedGradients, modelStats);
            
            // Overall gradient analysis score
            double gradientAnalysisScore = Math.max(Math.max(fgsmScore, pgdScore), cwScore);
            
            results.put("gradientNorm", gradientNorm);
            results.put("fgsmScore", fgsmScore);
            results.put("pgdScore", pgdScore);
            results.put("cwScore", cwScore);
            results.put("gradientAnalysisScore", gradientAnalysisScore);
            
            logger.debug("Gradient analysis completed. Gradient norm: {}, Analysis score: {}", 
                        gradientNorm, gradientAnalysisScore);
            
        } catch (Exception e) {
            logger.error("Error in gradient analysis", e);
            results.put("error", e.getMessage());
        }
        
        return results;
    }
    
    /**
     * Deploy Mahalanobis distance-based detection in neural network feature spaces
     */
    private Map<String, Object> performMahalanobisDistanceAnalysis(double[] input, ModelStatistics modelStats) {
        Map<String, Object> results = new HashMap<>();
        
        try {
            // Extract feature representations (simulated for different layers)
            List<double[]> featureRepresentations = extractFeatureRepresentations(input);
            
            double maxMahalanobisDistance = 0.0;
            List<Double> layerDistances = new ArrayList<>();
            
            for (int layer = 0; layer < featureRepresentations.size(); layer++) {
                double[] features = featureRepresentations.get(layer);
                
                // Calculate Mahalanobis distance from training distribution
                double mahalanobisDistance = calculateMahalanobisDistance(features, modelStats, layer);
                layerDistances.add(mahalanobisDistance);
                
                maxMahalanobisDistance = Math.max(maxMahalanobisDistance, mahalanobisDistance);
            }
            
            // Determine if distance exceeds threshold
            boolean isAnomalous = maxMahalanobisDistance > mahalanobisThreshold;
            double mahalanobisScore = Math.min(1.0, maxMahalanobisDistance / mahalanobisThreshold);
            
            results.put("maxMahalanobisDistance", maxMahalanobisDistance);
            results.put("layerDistances", layerDistances);
            results.put("isAnomalous", isAnomalous);
            results.put("mahalanobisScore", mahalanobisScore);
            
            logger.debug("Mahalanobis distance analysis completed. Max distance: {}, Score: {}", 
                        maxMahalanobisDistance, mahalanobisScore);
            
        } catch (Exception e) {
            logger.error("Error in Mahalanobis distance analysis", e);
            results.put("error", e.getMessage());
        }
        
        return results;
    }
    
    /**
     * Perform reconstruction-based detection using autoencoder approach
     */
    private Map<String, Object> performReconstructionErrorAnalysis(double[] input, ModelStatistics modelStats) {
        Map<String, Object> results = new HashMap<>();
        
        try {
            // Reconstruct input using autoencoder (simulated)
            double[] reconstructed = reconstructInput(input, modelStats);
            
            // Calculate reconstruction error
            double reconstructionError = calculateL2Distance(input, reconstructed);
            
            // Calculate normalized reconstruction error
            double normalizedError = reconstructionError / calculateL2Norm(input);
            
            // Determine if reconstruction error is anomalous
            boolean isAnomalous = reconstructionError > reconstructionErrorThreshold;
            double reconstructionScore = Math.min(1.0, reconstructionError / reconstructionErrorThreshold);
            
            // Additional reconstruction metrics
            double maxElementwiseError = calculateMaxElementwiseError(input, reconstructed);
            double meanSquaredError = calculateMeanSquaredError(input, reconstructed);
            
            results.put("reconstructionError", reconstructionError);
            results.put("normalizedError", normalizedError);
            results.put("isAnomalous", isAnomalous);
            results.put("reconstructionScore", reconstructionScore);
            results.put("maxElementwiseError", maxElementwiseError);
            results.put("meanSquaredError", meanSquaredError);
            
            logger.debug("Reconstruction error analysis completed. Error: {}, Score: {}", 
                        reconstructionError, reconstructionScore);
            
        } catch (Exception e) {
            logger.error("Error in reconstruction error analysis", e);
            results.put("error", e.getMessage());
        }
        
        return results;
    }
    
    /**
     * Perform statistical tests for adversarial detection
     */
    private Map<String, Object> performStatisticalTests(double[] input, ModelStatistics modelStats) {
        Map<String, Object> results = new HashMap<>();
        
        try {
            // Statistical properties of the input
            DescriptiveStatistics stats = new DescriptiveStatistics(input);
            
            // Compare with expected distribution statistics
            double meanDeviation = Math.abs(stats.getMean() - modelStats.getMeanInputValue());
            double stdDeviation = Math.abs(stats.getStandardDeviation() - modelStats.getStdInputValue());
            double rangeDeviation = Math.abs((stats.getMax() - stats.getMin()) - modelStats.getExpectedRange());
            
            // Calculate statistical anomaly score
            double statisticalAnomalyScore = (meanDeviation + stdDeviation + rangeDeviation) / 3.0;
            
            // Input value distribution analysis
            double[] inputDistribution = calculateInputDistribution(input);
            double distributionScore = compareDistributions(inputDistribution, modelStats.getExpectedDistribution());
            
            // Overall statistical score
            double overallStatisticalScore = Math.max(statisticalAnomalyScore, distributionScore);
            
            results.put("meanDeviation", meanDeviation);
            results.put("stdDeviation", stdDeviation);
            results.put("rangeDeviation", rangeDeviation);
            results.put("statisticalAnomalyScore", statisticalAnomalyScore);
            results.put("distributionScore", distributionScore);
            results.put("overallStatisticalScore", overallStatisticalScore);
            
            logger.debug("Statistical tests completed. Statistical score: {}", overallStatisticalScore);
            
        } catch (Exception e) {
            logger.error("Error in statistical tests", e);
            results.put("error", e.getMessage());
        }
        
        return results;
    }
    
    /**
     * Calculate ensemble decision combining all detection methods
     */
    private double calculateEnsembleScore(Map<String, Object> gradientResults,
                                        Map<String, Object> mahalanobisResults,
                                        Map<String, Object> reconstructionResults,
                                        Map<String, Object> statisticalResults) {
        double totalScore = 0.0;
        
        // Gradient analysis contribution
        Double gradientScore = (Double) gradientResults.get("gradientAnalysisScore");
        if (gradientScore != null) {
            totalScore += gradientAnalysisWeight * gradientScore;
        }
        
        // Mahalanobis distance contribution
        Double mahalanobisScore = (Double) mahalanobisResults.get("mahalanobisScore");
        if (mahalanobisScore != null) {
            totalScore += mahalanobisWeight * mahalanobisScore;
        }
        
        // Reconstruction error contribution
        Double reconstructionScore = (Double) reconstructionResults.get("reconstructionScore");
        if (reconstructionScore != null) {
            totalScore += reconstructionWeight * reconstructionScore;
        }
        
        // Statistical tests contribution
        Double statisticalScore = (Double) statisticalResults.get("overallStatisticalScore");
        if (statisticalScore != null) {
            totalScore += statisticalWeight * Math.min(1.0, statisticalScore);
        }
        
        return Math.min(1.0, totalScore);
    }
    
    /**
     * Get or compute model statistics for caching
     */
    private ModelStatistics getOrComputeModelStatistics(String modelId, Map<String, Object> modelMetadata) {
        return modelStatsCache.computeIfAbsent(modelId, id -> {
            logger.info("Computing model statistics for model: {}", id);
            return new ModelStatistics(modelMetadata);
        });
    }
    
    // Helper methods for detection algorithms
    
    private double[] computeSimulatedGradients(double[] input) {
        // Simulate gradient computation - in practice, this would use actual model gradients
        double[] gradients = new double[input.length];
        Random random = new Random(42);
        
        for (int i = 0; i < input.length; i++) {
            gradients[i] = random.nextGaussian() * 0.1;
        }
        
        return gradients;
    }
    
    private double detectFGSMPattern(double[] gradients, ModelStatistics modelStats) {
        // Detect Fast Gradient Sign Method patterns
        double maxGradient = Arrays.stream(gradients).map(Math::abs).max().orElse(0.0);
        return Math.min(1.0, maxGradient / perturbationThreshold);
    }
    
    private double detectPGDPattern(double[] input, double[] gradients, ModelStatistics modelStats) {
        // Detect Projected Gradient Descent patterns
        double gradientVariance = calculateVariance(gradients);
        return Math.min(1.0, gradientVariance * 10.0);
    }
    
    private double detectCWPattern(double[] input, double[] gradients, ModelStatistics modelStats) {
        // Detect Carlini & Wagner patterns
        double gradientEntropy = calculateEntropy(gradients);
        return Math.min(1.0, gradientEntropy / 5.0);
    }
    
    private List<double[]> extractFeatureRepresentations(double[] input) {
        // Simulate feature extraction from different layers
        List<double[]> features = new ArrayList<>();
        
        // Layer 1 features
        double[] layer1 = new double[input.length / 2];
        for (int i = 0; i < layer1.length; i++) {
            layer1[i] = input[i * 2] + input[i * 2 + 1];
        }
        features.add(layer1);
        
        // Layer 2 features
        double[] layer2 = new double[layer1.length / 2];
        for (int i = 0; i < layer2.length && i * 2 + 1 < layer1.length; i++) {
            layer2[i] = layer1[i * 2] * layer1[i * 2 + 1];
        }
        features.add(layer2);
        
        return features;
    }
    
    private double calculateMahalanobisDistance(double[] features, ModelStatistics modelStats, int layer) {
        // Simplified Mahalanobis distance calculation
        // In practice, this would use the actual covariance matrix from training data
        double[] mean = modelStats.getLayerMeans().get(layer);
        if (mean == null) {
            mean = new double[features.length];
        }
        
        double distance = 0.0;
        for (int i = 0; i < features.length && i < mean.length; i++) {
            distance += Math.pow(features[i] - mean[i], 2);
        }
        
        return Math.sqrt(distance);
    }
    
    private double[] reconstructInput(double[] input, ModelStatistics modelStats) {
        // Simulate autoencoder reconstruction
        double[] reconstructed = new double[input.length];
        Random random = new Random(42);
        
        for (int i = 0; i < input.length; i++) {
            reconstructed[i] = input[i] + random.nextGaussian() * 0.01; // Add small noise
        }
        
        return reconstructed;
    }
    
    // Utility methods
    
    private double calculateL2Norm(double[] vector) {
        return Math.sqrt(Arrays.stream(vector).map(x -> x * x).sum());
    }
    
    private double calculateL2Distance(double[] a, double[] b) {
        double sum = 0.0;
        for (int i = 0; i < Math.min(a.length, b.length); i++) {
            sum += Math.pow(a[i] - b[i], 2);
        }
        return Math.sqrt(sum);
    }
    
    private double calculateMaxElementwiseError(double[] original, double[] reconstructed) {
        double maxError = 0.0;
        for (int i = 0; i < Math.min(original.length, reconstructed.length); i++) {
            maxError = Math.max(maxError, Math.abs(original[i] - reconstructed[i]));
        }
        return maxError;
    }
    
    private double calculateMeanSquaredError(double[] original, double[] reconstructed) {
        double sum = 0.0;
        int count = Math.min(original.length, reconstructed.length);
        for (int i = 0; i < count; i++) {
            sum += Math.pow(original[i] - reconstructed[i], 2);
        }
        return sum / count;
    }
    
    private double calculateVariance(double[] array) {
        DescriptiveStatistics stats = new DescriptiveStatistics(array);
        return stats.getVariance();
    }
    
    private double calculateEntropy(double[] array) {
        // Simplified entropy calculation
        Map<Integer, Integer> frequency = new HashMap<>();
        for (double value : array) {
            int bucket = (int) (value * 100); // Discretize
            frequency.merge(bucket, 1, Integer::sum);
        }
        
        double entropy = 0.0;
        int total = array.length;
        for (int count : frequency.values()) {
            double probability = (double) count / total;
            entropy -= probability * Math.log(probability);
        }
        
        return entropy;
    }
    
    private double[] calculateInputDistribution(double[] input) {
        // Simple histogram-based distribution
        int bins = 10;
        double[] distribution = new double[bins];
        double min = Arrays.stream(input).min().orElse(0.0);
        double max = Arrays.stream(input).max().orElse(1.0);
        double binWidth = (max - min) / bins;
        
        for (double value : input) {
            int bin = Math.min(bins - 1, (int) ((value - min) / binWidth));
            distribution[bin]++;
        }
        
        // Normalize
        for (int i = 0; i < distribution.length; i++) {
            distribution[i] /= input.length;
        }
        
        return distribution;
    }
    
    private double compareDistributions(double[] dist1, double[] dist2) {
        if (dist2 == null) return 0.0;
        
        double difference = 0.0;
        for (int i = 0; i < Math.min(dist1.length, dist2.length); i++) {
            difference += Math.abs(dist1[i] - dist2[i]);
        }
        
        return difference / Math.min(dist1.length, dist2.length);
    }
    
    private Map<String, String> buildDetectionDetails(Map<String, Object> gradientResults,
                                                     Map<String, Object> mahalanobisResults,
                                                     Map<String, Object> reconstructionResults,
                                                     Map<String, Object> statisticalResults) {
        Map<String, String> details = new HashMap<>();
        
        details.put("gradientAnalysisScore", String.valueOf(gradientResults.get("gradientAnalysisScore")));
        details.put("fgsmScore", String.valueOf(gradientResults.get("fgsmScore")));
        details.put("pgdScore", String.valueOf(gradientResults.get("pgdScore")));
        details.put("cwScore", String.valueOf(gradientResults.get("cwScore")));
        details.put("maxMahalanobisDistance", String.valueOf(mahalanobisResults.get("maxMahalanobisDistance")));
        details.put("reconstructionError", String.valueOf(reconstructionResults.get("reconstructionError")));
        details.put("statisticalAnomalyScore", String.valueOf(statisticalResults.get("overallStatisticalScore")));
        
        return details;
    }
    
    private double calculateConfidenceScore(double threatScore) {
        if (threatScore > 0.8) return 0.95;
        if (threatScore > 0.6) return 0.85;
        if (threatScore > 0.4) return 0.75;
        if (threatScore > 0.2) return 0.65;
        return 0.5;
    }
    
    /**
     * Inner class to store model statistics
     */
    private static class ModelStatistics {
        private final double meanInputValue;
        private final double stdInputValue;
        private final double expectedRange;
        private final double[] expectedDistribution;
        private final List<double[]> layerMeans;
        
        public ModelStatistics(Map<String, Object> modelMetadata) {
            // Initialize with default values or from metadata
            this.meanInputValue = 0.0;
            this.stdInputValue = 1.0;
            this.expectedRange = 2.0;
            this.expectedDistribution = new double[]{0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.1, 0.1, 0.1, 0.1};
            this.layerMeans = Arrays.asList(
                new double[]{0.0, 0.0, 0.0, 0.0},
                new double[]{0.0, 0.0}
            );
        }
        
        public double getMeanInputValue() { return meanInputValue; }
        public double getStdInputValue() { return stdInputValue; }
        public double getExpectedRange() { return expectedRange; }
        public double[] getExpectedDistribution() { return expectedDistribution; }
        public List<double[]> getLayerMeans() { return layerMeans; }
    }
}